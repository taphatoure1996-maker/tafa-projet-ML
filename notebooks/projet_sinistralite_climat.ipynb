{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de l'Impact des Conditions Climatiques sur la Sinistralité Automobile\n",
    "\n",
    "## Contexte du Projet\n",
    "\n",
    "Ce projet vise à analyser l'**impact des conditions climatiques sur la sinistralité automobile** en utilisant des méthodes de réduction de dimension et de machine learning.\n",
    "\n",
    "### Objectifs\n",
    "\n",
    "1. Construction d'une base jointe (assurance × climat)\n",
    "2. Définition des variables cibles (fréquence et gravité)\n",
    "3. Analyse descriptive complète\n",
    "4. Réduction de dimension (ACP/PLS)\n",
    "5. Modélisation prédictive\n",
    "6. Interprétation et conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Import des modules personnalisés\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src import data_preprocessing as dp\n",
    "from src import feature_engineering as fe\n",
    "from src import dimension_reduction as dr\n",
    "from src import models as md\n",
    "from src import evaluation as ev\n",
    "\n",
    "print(\"Bibliothèques chargées avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et Préparation des Données\n",
    "\n",
    "### 1.1 Chargement des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de toutes les données\n",
    "donnees = dp.charger_toutes_donnees('..')\n",
    "\n",
    "df_polices = donnees['polices']\n",
    "df_sinistres = donnees['sinistres']\n",
    "df_climat = donnees['climat']\n",
    "df_communes = donnees['communes']\n",
    "\n",
    "print(\"\\nAperçu des polices:\")\n",
    "print(df_polices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Nettoyage et préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyer les polices\n",
    "df_polices_clean = dp.nettoyer_donnees_polices(df_polices)\n",
    "\n",
    "# Nettoyer les sinistres\n",
    "df_sinistres_clean = dp.nettoyer_donnees_sinistres(df_sinistres)\n",
    "\n",
    "# Agréger les sinistres par police\n",
    "df_sinistres_agg = dp.agregation_sinistres_par_police(df_sinistres_clean)\n",
    "\n",
    "print(\"\\nStatistiques des sinistres agrégés:\")\n",
    "print(df_sinistres_agg.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Construction de la base finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joindre polices et sinistres\n",
    "df_base = fe.joindre_polices_sinistres(df_polices_clean, df_sinistres_agg)\n",
    "\n",
    "# Préparer les données climatiques\n",
    "df_climat_prep, variables_climat = dp.preparer_variables_climatiques(df_climat)\n",
    "df_climat_agg = fe.agregation_climat_par_dept_annee(df_climat_prep, variables_climat)\n",
    "\n",
    "# Joindre avec les données climatiques\n",
    "df_finale = fe.joindre_avec_climat(df_base, df_climat_agg)\n",
    "\n",
    "# Créer des variables dérivées\n",
    "df_finale = fe.creer_variables_derivees(df_finale)\n",
    "\n",
    "print(\"\\nDimensions de la base finale:\", df_finale.shape)\n",
    "print(\"\\nAperçu de la base finale:\")\n",
    "print(df_finale.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse Descriptive Complète\n",
    "\n",
    "### 2.1 Distribution de la fréquence des sinistres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la variable cible (fréquence)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Indicateur binaire\n",
    "df_finale['a_sinistre'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Distribution de la Sinistralité (0/1)')\n",
    "axes[0].set_xlabel('A eu un sinistre')\n",
    "axes[0].set_ylabel('Nombre de polices')\n",
    "\n",
    "# Nombre de sinistres\n",
    "df_finale[df_finale['nb_sinistres_total'] > 0]['nb_sinistres_total'].hist(bins=20, ax=axes[1])\n",
    "axes[1].set_title('Distribution du Nombre de Sinistres (si > 0)')\n",
    "axes[1].set_xlabel('Nombre de sinistres')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Taux de sinistralité: {df_finale['a_sinistre'].mean()*100:.2f}%\")\n",
    "print(f\"Nombre moyen de sinistres (si sinistre): {df_finale[df_finale['nb_sinistres_total'] > 0]['nb_sinistres_total'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distribution de la gravité des sinistres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser uniquement les polices avec sinistre\n",
    "df_avec_sinistre = df_finale[df_finale['a_sinistre'] == 1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution du montant total\n",
    "df_avec_sinistre['montant_total'].hist(bins=50, ax=axes[0])\n",
    "axes[0].set_title('Distribution du Montant Total des Sinistres')\n",
    "axes[0].set_xlabel('Montant (€)')\n",
    "axes[0].set_ylabel('Fréquence')\n",
    "\n",
    "# Distribution log du montant\n",
    "np.log1p(df_avec_sinistre['montant_total']).hist(bins=50, ax=axes[1])\n",
    "axes[1].set_title('Distribution Log du Montant Total')\n",
    "axes[1].set_xlabel('Log(Montant + 1)')\n",
    "axes[1].set_ylabel('Fréquence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Montant moyen des sinistres: {df_avec_sinistre['montant_total'].mean():.2f}€\")\n",
    "print(f\"Montant médian: {df_avec_sinistre['montant_total'].median():.2f}€\")\n",
    "print(f\"Montant max: {df_avec_sinistre['montant_total'].max():.2f}€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Analyse par variables d'assurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinistralité par couverture\n",
    "sinistralite_par_couverture = df_finale.groupby('pol_coverage').agg({\n",
    "    'a_sinistre': ['mean', 'count'],\n",
    "    'montant_total': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"Sinistralité par type de couverture:\")\n",
    "print(sinistralite_par_couverture)\n",
    "\n",
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Par usage\n",
    "df_finale.groupby('pol_usage')['a_sinistre'].mean().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Taux de Sinistralité par Usage')\n",
    "axes[0].set_ylabel('Taux')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Par âge véhicule\n",
    "if 'vh_age_cat' in df_finale.columns:\n",
    "    df_finale.groupby('vh_age_cat')['a_sinistre'].mean().plot(kind='bar', ax=axes[1])\n",
    "    axes[1].set_title('Taux de Sinistralité par Âge Véhicule')\n",
    "    axes[1].set_ylabel('Taux')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Par âge conducteur\n",
    "if 'drv_age1_cat' in df_finale.columns:\n",
    "    df_finale.groupby('drv_age1_cat')['a_sinistre'].mean().plot(kind='bar', ax=axes[2])\n",
    "    axes[2].set_title('Taux de Sinistralité par Âge Conducteur')\n",
    "    axes[2].set_ylabel('Taux')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Corrélation entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les variables numériques principales\n",
    "vars_numeriques = ['pol_bonus', 'pol_duration', 'drv_age1', 'drv_age_lic1',\n",
    "                   'vh_age', 'vh_din', 'vh_value', 'a_sinistre', 'nb_sinistres_total']\n",
    "vars_disponibles = [v for v in vars_numeriques if v in df_finale.columns]\n",
    "\n",
    "# Matrice de corrélation\n",
    "corr_matrix = df_finale[vars_disponibles].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Matrice de Corrélation - Variables Principales')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Description des variables climatiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les variables climatiques dans la base finale\n",
    "cols_climat = [col for col in df_finale.columns \n",
    "               if any(prefix in col for prefix in ['RR', 'TX', 'TN', 'TM', 'UN', 'FF'])]\n",
    "\n",
    "if len(cols_climat) > 0:\n",
    "    print(f\"Nombre de variables climatiques: {len(cols_climat)}\")\n",
    "    print(\"\\nStatistiques descriptives des principales variables climatiques:\")\n",
    "    print(df_finale[cols_climat[:10]].describe())\n",
    "    \n",
    "    # Corrélation entre climat et sinistralité\n",
    "    if len(cols_climat) >= 5:\n",
    "        climat_vs_sinistre = df_finale[cols_climat[:20] + ['a_sinistre']].corr()['a_sinistre'].sort_values(ascending=False)\n",
    "        print(\"\\nTop 10 corrélations climat-sinistralité:\")\n",
    "        print(climat_vs_sinistre[1:11])  # Exclure la corrélation avec soi-même\n",
    "else:\n",
    "    print(\"Aucune variable climatique trouvée dans la base finale.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Réduction de Dimension sur les Variables Climatiques\n",
    "\n",
    "### 3.1 Préparation des données climatiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner uniquement les observations avec données climatiques\n",
    "df_avec_climat = df_finale[cols_climat].dropna()\n",
    "\n",
    "# Limiter aux variables climatiques les plus importantes (pour performance)\n",
    "# Sélectionner max 50 variables\n",
    "cols_climat_reduced = cols_climat[:min(50, len(cols_climat))]\n",
    "X_climat = df_avec_climat[cols_climat_reduced]\n",
    "\n",
    "print(f\"Données climatiques pour ACP: {X_climat.shape}\")\n",
    "print(f\"Variables sélectionnées: {len(cols_climat_reduced)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardiser les variables climatiques\n",
    "X_climat_scaled, scaler_climat, feature_names_climat = dr.standardiser_variables(\n",
    "    X_climat, \n",
    "    feature_names=cols_climat_reduced\n",
    ")\n",
    "\n",
    "print(\"Standardisation effectuée.\")\n",
    "print(f\"Moyenne après standardisation: {X_climat_scaled.mean():.6f}\")\n",
    "print(f\"Écart-type après standardisation: {X_climat_scaled.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analyse en Composantes Principales (ACP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectuer l'ACP\n",
    "resultats_acp = dr.analyse_acp(\n",
    "    X_climat_scaled, \n",
    "    n_components=min(20, X_climat.shape[1]), \n",
    "    feature_names=feature_names_climat\n",
    ")\n",
    "\n",
    "# Visualiser la variance expliquée\n",
    "fig = dr.visualiser_variance_expliquee(resultats_acp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Interprétation des composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les loadings\n",
    "fig = dr.visualiser_loadings(resultats_acp['loadings'], n_components=5, n_vars=10)\n",
    "plt.show()\n",
    "\n",
    "# Interpréter les composantes\n",
    "interpretations = dr.interpreter_composantes_climat(resultats_acp['loadings'], n_components=5)\n",
    "for comp, interp in interpretations.items():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Partial Least Squares (PLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer y pour PLS (sinistralité)\n",
    "indices_climat = df_finale[cols_climat].dropna().index\n",
    "y_climat = df_finale.loc[indices_climat, 'a_sinistre']\n",
    "\n",
    "# Aligner X et y\n",
    "X_pls = X_climat_scaled\n",
    "y_pls = y_climat.values\n",
    "\n",
    "# Effectuer la PLS\n",
    "resultats_pls = dr.analyser_pls(\n",
    "    X_pls, \n",
    "    y_pls, \n",
    "    n_components=10, \n",
    "    feature_names=feature_names_climat\n",
    ")\n",
    "\n",
    "# Visualiser les loadings PLS\n",
    "fig = dr.visualiser_loadings(resultats_pls['loadings'], n_components=5, n_vars=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modélisation - Fréquence des Sinistres\n",
    "\n",
    "### 4.1 Préparation des données de modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les features pour la modélisation\n",
    "features = fe.selectionner_features_modelisation(df_finale, inclure_climat=True)\n",
    "\n",
    "print(f\"Nombre de features sélectionnées: {len(features)}\")\n",
    "print(f\"Features: {features[:20]}...\")  # Afficher les 20 premières\n",
    "\n",
    "# Préparer X et y\n",
    "X, y, indices = fe.preparer_donnees_modelisation(\n",
    "    df_finale, \n",
    "    features, \n",
    "    target='a_sinistre'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Division train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données\n",
    "X_train, X_test, y_train, y_test = md.diviser_donnees(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Modèles de classification\n",
    "\n",
    "#### 4.3.1 Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner la régression logistique\n",
    "model_logistic = md.entrainer_logistic_regression(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_logistic = model_logistic.predict(X_test)\n",
    "y_pred_proba_logistic = model_logistic.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Évaluation\n",
    "metriques_logistic = ev.evaluer_classification(y_test, y_pred_logistic, y_pred_proba_logistic)\n",
    "ev.afficher_metriques_classification(metriques_logistic, \"Régression Logistique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Régression Logistique Pénalisée (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner Lasso\n",
    "model_lasso = md.entrainer_logistic_penalisee(X_train, y_train, penalty='l1', C=0.1)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "y_pred_proba_lasso = model_lasso.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Évaluation\n",
    "metriques_lasso = ev.evaluer_classification(y_test, y_pred_lasso, y_pred_proba_lasso)\n",
    "ev.afficher_metriques_classification(metriques_lasso, \"Lasso Logistique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner Random Forest\n",
    "model_rf = md.entrainer_random_forest_classifier(X_train, y_train, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "y_pred_proba_rf = model_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Évaluation\n",
    "metriques_rf = ev.evaluer_classification(y_test, y_pred_rf, y_pred_proba_rf)\n",
    "ev.afficher_metriques_classification(metriques_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner XGBoost\n",
    "model_xgb = md.entrainer_xgboost_classifier(X_train, y_train, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "y_pred_proba_xgb = model_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Évaluation\n",
    "metriques_xgb = ev.evaluer_classification(y_test, y_pred_xgb, y_pred_proba_xgb)\n",
    "ev.afficher_metriques_classification(metriques_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Comparaison des modèles de fréquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler les résultats\n",
    "resultats_frequence = {\n",
    "    'Logistic Regression': metriques_logistic,\n",
    "    'Lasso': metriques_lasso,\n",
    "    'Random Forest': metriques_rf,\n",
    "    'XGBoost': metriques_xgb\n",
    "}\n",
    "\n",
    "# Comparaison\n",
    "df_comp_freq = ev.comparer_modeles(resultats_frequence, metrique='roc_auc')\n",
    "\n",
    "# Visualisation\n",
    "ev.visualiser_comparaison_modeles(resultats_frequence, \n",
    "                                   metriques_a_comparer=['accuracy', 'roc_auc', 'f1_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Courbe ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes ROC pour tous les modèles\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "for nom, y_proba in [('Logistic', y_pred_proba_logistic), \n",
    "                      ('Lasso', y_pred_proba_lasso),\n",
    "                      ('Random Forest', y_pred_proba_rf), \n",
    "                      ('XGBoost', y_pred_proba_xgb)]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{nom} (AUC = {auc:.4f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('Taux de Faux Positifs')\n",
    "plt.ylabel('Taux de Vrais Positifs')\n",
    "plt.title('Courbes ROC - Comparaison des Modèles')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modélisation - Gravité des Sinistres\n",
    "\n",
    "### 5.1 Préparation des données (seulement polices avec sinistre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer uniquement les polices avec sinistre\n",
    "df_gravite = df_finale[df_finale['a_sinistre'] == 1].copy()\n",
    "\n",
    "# Préparer X et y pour la gravité\n",
    "X_grav, y_grav, indices_grav = fe.preparer_donnees_modelisation(\n",
    "    df_gravite,\n",
    "    features,\n",
    "    target='montant_total'\n",
    ")\n",
    "\n",
    "print(f\"\\nDonnées gravité: {X_grav.shape}\")\n",
    "print(f\"Montant moyen: {y_grav.mean():.2f}€\")\n",
    "\n",
    "# Division train/test\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = md.diviser_donnees(\n",
    "    X_grav, y_grav, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Modèles de régression\n",
    "\n",
    "#### 5.2.1 Régression Linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner régression linéaire\n",
    "model_linear = md.entrainer_regression_lineaire(X_train_g, y_train_g)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_linear = model_linear.predict(X_test_g)\n",
    "\n",
    "# Évaluation\n",
    "metriques_linear = ev.evaluer_regression(y_test_g, y_pred_linear)\n",
    "ev.afficher_metriques_regression(metriques_linear, \"Régression Linéaire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner Ridge\n",
    "model_ridge = md.entrainer_regression_penalisee(X_train_g, y_train_g, method='ridge', alpha=1.0)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_ridge = model_ridge.predict(X_test_g)\n",
    "\n",
    "# Évaluation\n",
    "metriques_ridge = ev.evaluer_regression(y_test_g, y_pred_ridge)\n",
    "ev.afficher_metriques_regression(metriques_ridge, \"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner Random Forest\n",
    "model_rf_reg = md.entrainer_random_forest_regressor(X_train_g, y_train_g, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_rf_reg = model_rf_reg.predict(X_test_g)\n",
    "\n",
    "# Évaluation\n",
    "metriques_rf_reg = ev.evaluer_regression(y_test_g, y_pred_rf_reg)\n",
    "ev.afficher_metriques_regression(metriques_rf_reg, \"Random Forest Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner XGBoost\n",
    "model_xgb_reg = md.entrainer_xgboost_regressor(X_train_g, y_train_g, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test_g)\n",
    "\n",
    "# Évaluation\n",
    "metriques_xgb_reg = ev.evaluer_regression(y_test_g, y_pred_xgb_reg)\n",
    "ev.afficher_metriques_regression(metriques_xgb_reg, \"XGBoost Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Comparaison des modèles de gravité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler les résultats\n",
    "resultats_gravite = {\n",
    "    'Linear Regression': metriques_linear,\n",
    "    'Ridge': metriques_ridge,\n",
    "    'Random Forest': metriques_rf_reg,\n",
    "    'XGBoost': metriques_xgb_reg\n",
    "}\n",
    "\n",
    "# Comparaison\n",
    "df_comp_grav = ev.comparer_modeles(resultats_gravite, metrique='r2')\n",
    "\n",
    "# Visualisation\n",
    "ev.visualiser_comparaison_modeles(resultats_gravite, \n",
    "                                   metriques_a_comparer=['r2', 'mae', 'rmse'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualisation des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions vs réelles pour le meilleur modèle\n",
    "ev.graphique_predictions_vs_reelles(y_test_g, y_pred_xgb_reg)\n",
    "plt.show()\n",
    "\n",
    "# Résidus\n",
    "ev.graphique_residus(y_test_g, y_pred_xgb_reg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interprétation des Résultats\n",
    "\n",
    "### 6.1 Feature Importance - Fréquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance pour Random Forest (fréquence)\n",
    "importance_rf = md.extraire_feature_importance(model_rf, features)\n",
    "print(\"\\nTop 20 Features les plus importantes (Random Forest - Fréquence):\")\n",
    "print(importance_rf.head(20))\n",
    "\n",
    "# Visualisation\n",
    "ev.visualiser_feature_importance(importance_rf, top_n=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Feature Importance - Gravité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance pour Random Forest (gravité)\n",
    "importance_rf_grav = md.extraire_feature_importance(model_rf_reg, features)\n",
    "print(\"\\nTop 20 Features les plus importantes (Random Forest - Gravité):\")\n",
    "print(importance_rf_grav.head(20))\n",
    "\n",
    "# Visualisation\n",
    "ev.visualiser_feature_importance(importance_rf_grav, top_n=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 SHAP Values (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les SHAP values pour le modèle Random Forest (fréquence)\n",
    "try:\n",
    "    shap_values = ev.calculer_shap_values(model_rf, X_test, feature_names=features, max_display=20)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"SHAP values non calculées: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions et Recommandations pour un Assureur\n",
    "\n",
    "### 7.1 Synthèse des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SYNTHÈSE DES RÉSULTATS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. MODÉLISATION DE LA FRÉQUENCE DES SINISTRES\")\n",
    "print(\"-\" * 80)\n",
    "for nom, metriques in resultats_frequence.items():\n",
    "    print(f\"{nom:25s} - AUC: {metriques['roc_auc']:.4f}, Accuracy: {metriques['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\n2. MODÉLISATION DE LA GRAVITÉ DES SINISTRES\")\n",
    "print(\"-\" * 80)\n",
    "for nom, metriques in resultats_gravite.items():\n",
    "    print(f\"{nom:25s} - R²: {metriques['r2']:.4f}, RMSE: {metriques['rmse']:.2f}€\")\n",
    "\n",
    "print(\"\\n3. MEILLEUR MODÈLE PAR TÂCHE\")\n",
    "print(\"-\" * 80)\n",
    "best_freq = max(resultats_frequence.items(), key=lambda x: x[1]['roc_auc'])\n",
    "best_grav = max(resultats_gravite.items(), key=lambda x: x[1]['r2'])\n",
    "print(f\"Fréquence : {best_freq[0]} (AUC = {best_freq[1]['roc_auc']:.4f})\")\n",
    "print(f\"Gravité   : {best_grav[0]} (R² = {best_grav[1]['r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Recommandations opérationnelles\n",
    "\n",
    "#### Facteurs de risque identifiés\n",
    "\n",
    "Sur la base de l'analyse des features importance et des modèles, voici les principaux facteurs de risque :\n",
    "\n",
    "**Facteurs assurantiels :**\n",
    "- Bonus-malus du conducteur\n",
    "- Âge du conducteur\n",
    "- Expérience de conduite\n",
    "- Âge et puissance du véhicule\n",
    "- Usage du véhicule\n",
    "\n",
    "**Facteurs climatiques :**\n",
    "- Les variables climatiques ont été réduites en composantes principales\n",
    "- Certaines composantes montrent une corrélation avec la sinistralité\n",
    "- L'impact varie selon les régions et périodes\n",
    "\n",
    "#### Applications pour l'assureur\n",
    "\n",
    "1. **Tarification** : Ajuster les primes en fonction des facteurs identifiés\n",
    "2. **Souscription** : Améliorer le processus de sélection des risques\n",
    "3. **Prévention** : Cibler les actions de prévention sur les profils à risque\n",
    "4. **Provisionnement** : Mieux estimer les réserves nécessaires\n",
    "\n",
    "#### Limites et perspectives\n",
    "\n",
    "- Les données climatiques pourraient être affinées (granularité temporelle)\n",
    "- D'autres variables externes pourraient être intégrées (trafic, infrastructure)\n",
    "- Les modèles pourraient être améliorés avec plus de données historiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde des Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les principaux résultats\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Créer un dossier pour les résultats\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# Sauvegarder les modèles\n",
    "with open('../results/best_model_frequence.pkl', 'wb') as f:\n",
    "    pickle.dump(model_xgb, f)\n",
    "\n",
    "with open('../results/best_model_gravite.pkl', 'wb') as f:\n",
    "    pickle.dump(model_xgb_reg, f)\n",
    "\n",
    "# Sauvegarder les résultats de comparaison\n",
    "df_comp_freq.to_csv('../results/comparaison_modeles_frequence.csv', index=False)\n",
    "df_comp_grav.to_csv('../results/comparaison_modeles_gravite.csv', index=False)\n",
    "\n",
    "# Sauvegarder les feature importances\n",
    "importance_rf.to_csv('../results/feature_importance_frequence.csv', index=False)\n",
    "importance_rf_grav.to_csv('../results/feature_importance_gravite.csv', index=False)\n",
    "\n",
    "print(\"Résultats sauvegardés dans le dossier 'results/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fin du Notebook\n",
    "\n",
    "Ce notebook a présenté une analyse complète de l'impact des conditions climatiques sur la sinistralité automobile, incluant :\n",
    "\n",
    "1. ✅ Construction de la base jointe\n",
    "2. ✅ Analyse descriptive\n",
    "3. ✅ Réduction de dimension (ACP/PLS)\n",
    "4. ✅ Modélisation de la fréquence\n",
    "5. ✅ Modélisation de la gravité\n",
    "6. ✅ Comparaison et sélection des modèles\n",
    "7. ✅ Interprétation des résultats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
